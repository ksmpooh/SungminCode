{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob,gzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting Data Location\n",
    "\n",
    "### essential set : \n",
    "1. wDir\n",
    "2. vcfDir\n",
    "\n",
    "### input data in (wDir + INPUTs/)\n",
    "1. ped file\n",
    "2. chunk index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir\n",
    "wDir = \"/DATA/smkim/KCHIP_130K/Asso/\"\n",
    "vcfDir = \"/LaCie/ghyoon/OAS/\"\n",
    "outdir =  wDir + \"RESULTs/\"\n",
    "inDir = wDir + \"INPUTs/\"\n",
    "scriptDir = wDir +\"SCRIPTs/\"\n",
    "versions = [\"V1\",\"V2\"]\n",
    "concepts = []\n",
    "phenotypes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fucntion related File IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileRead(fileIn):\n",
    "    print(\"Read File : \"+fileIn)\n",
    "    if not os.path.exists(fileIn):\n",
    "        print(\"Error! File does not exist in path :\" + fileIn)\n",
    "        return 0\n",
    "    fileIO = open(fileIn,'r')\n",
    "    InData = [f.replace(\"\\n\",\"\").replace(\"\\r\",\"\") for f in fileIO]\n",
    "    \n",
    "    fileIO.close()\n",
    "    return InData\n",
    "def make_dir(path):\n",
    "    print(\"Make Dir path : \"+ path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(\"Make Dir Success\")\n",
    "        return path\n",
    "    print(\"Already exist Dir! pass this step!\")\n",
    "    return path  \n",
    "\n",
    "def gzRead(fileIn):\n",
    "    print(\"Read gz File : \"+fileIn)\n",
    "    if not os.path.exists(fileIn):\n",
    "        print(\"Error! File does not exist in path :\" + fileIn)\n",
    "        return 0\n",
    "    fileIO = gzip.open(fileIn,'r')\n",
    "    inData = [f.replace(\"\\n\",\"\").replace(\"\\r\",\"\") for f in fileIO]\n",
    "    return inData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print option to select when using Switch : failure....TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_option():\n",
    "    print(\"please, Select option you want.\")\n",
    "    print(\"1. Make Shell scipt\")\n",
    "    print(\"2. Merge result file \")\n",
    "    print(\"3. Merge result file(using pandas) \")\n",
    "    print(\"4. Nothing\")\n",
    "    value = int(input(\"Input : \"))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main process function for association (asso, merge)\n",
    "### 3 options \n",
    "1. asso\n",
    "2. merge epacts \n",
    "3. merge epacts(pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_assoSh(pedIn,chunksSplit):\n",
    "\n",
    "    print(\"Make_assosh...\")\n",
    "    for phenotype in phenotypes:\n",
    "        shDir = make_dir(scriptDir + \"aasoQT_\"+phenotype+\"/\")\n",
    "        traitDir = make_dir(outdir + \"assoRESULTs/\"+phenotype+\"/\")\n",
    "        for version in versions:\n",
    "            for region_list in chunksSplit:\n",
    "                \n",
    "                region = region_list[0].replace(\"chr\",\"\")+\":\"+region_list[1]+\"-\"+region_list[2]\n",
    "                vcfData = vcfDir + region_list[0]+ \"_\"+region_list[1] +\"_\"+region_list[2]+\"_\"+version+\"_annoINFO_filINFO0.8.vcf.gz\"\n",
    "                runType = \"_q.linear_\" + phenotype+\"_\"+concept\n",
    "                \n",
    "                assoOut = vcfData.replace(vcfDir,traitDir).replace(\"_annoINFO_filINFO0.8.vcf.gz\",runType)\n",
    "                shOut = vcfData.replace(vcfDir,shDir).replace(\"_annoINFO_filINFO0.8.vcf.gz\",runType + \"_assoEPACTs.sh\")\n",
    "\n",
    "                with open(shOut, 'w') as shWrite:\n",
    "                    shWrite.write(\"epacts-single --vcf \"+ vcfData + \" --ped \" + pedIn +\n",
    "                                  \" --pheno \"+ phenotype + \" --test q.linear --run 8 --field DS --min-mac 5 -min-callrate 0.95 -no-plot\"+\n",
    "                                  \" --region \" + region +\n",
    "                                  \" --missing NA --out \"+ assoOut + \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_asso(chunks):\n",
    "    print(\"merge_ass......\")\n",
    "    mergeDir = make_dir(outDir + \"assoMERGEs/\")\n",
    "    for phenotype in phenotypes:\n",
    "        traitDir = make_dir(outdir + \"assoRESULTs/\"+phenotype+\"/\")\n",
    "        mergeOut = make_dir(mergeDir + phenotype+\"/\")\n",
    "        for version in versions:\n",
    "            mergeOut = mergeOut + phenotype+\"_\"+version+\"_mergeData.txt\"\n",
    "            with open(mergeOut,'w') as mergeWrite:\n",
    "                for i,chunk in enumerate(chunks):\n",
    "                    epactsIn = traitDir + chunk + \"_\" +version + \"_q.linear_\"+phenotype + \".epacts.gz\"\n",
    "                    if i != 0 and os.path.isfile(epactsIn):\n",
    "                        mergeData = gzRead(epactsIn)\n",
    "                        mergeWrite.write(\"\\n\".join(mergeData[1:])+\"\\n\")\n",
    "                    if i == 0 :\n",
    "                        mergeData = gzRead(epactsIn)\n",
    "                        mergeWrite.write(\"\\n\".join(mergeData[0:])+\"\\n\")\n",
    "\n",
    "                    if os.path.isfile(epactsIn):\n",
    "                        mergeData = gzRead(epactsIn)\n",
    "                        mergeWrite.write(\"\\n\".join(mergeData[1:])+\"\\n\")\n",
    "                    else:\n",
    "                        os.system(\"rm -rf \" +mergeOut)\n",
    "                        break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pandas가 있을 경우\n",
    "import pandas as pd\n",
    "def merge_asso_pd(chunks):\n",
    "    print(\"merge_asso using pandas......\")\n",
    "    mergeDir = make_dir(outDir + \"assoMERGEs/\")\n",
    "    for phenotype in phenotypes:\n",
    "        traitDir = make_dir(outdir + \"assoRESULTs/\"+phenotype+\"/\")\n",
    "        mergeOut = make_dir(mergeDir + phenotype + \"/\" )\n",
    "        for version in versions:\n",
    "            df = pd.DataFrame()          \n",
    "            mergeOut = mergeOut + phenotype+\"_\"+version+\"_mergeData.txt\"\n",
    "            for chunk in chunks:\n",
    "                epactsIn = traitDir + chunk + \"_\" +version+\"_q.linear_\"+phenotype+\".epacts.gz\" \n",
    "                tmp = pd.read_csv(epactsIn,compression = 'gzip',delim_whitespace = True, error_bad_lines = False)\n",
    "                df = pd.concat(df,tmp,axis=0,ignore_index=True)\n",
    "            df.to_csv(mergeOut, index = False, sep = '\\t',quotechar = \"\\\"\")\n",
    "            print(\"TO_csv path : \" + mergeOut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Chunk = inDir+\"imputation.IMPUTE4.POS.50K_20181114_Final.txt\"\n",
    "    Ori_chunksfile = [f.split(\"\\t\") for f in fileRead(Chunk)]\n",
    "    chunks = [r[1] for r in Ori_chunksfile[1:]]\n",
    "    chunksSplit = [r.split(\"_\") for r in chunks]\n",
    "    \n",
    "    pedfile = \"KCHIP130K_transformation_hematological_20190903.ped\"\n",
    "    pedIn = inDir + pedfile\n",
    "    \n",
    "    value = 0\n",
    "    while(value !=4 ):\n",
    "        value = print_option()\n",
    "        if value == 1 :\n",
    "            make_assoSh(pedIn,chunksSplit)\n",
    "        elif value == 2 :\n",
    "            merge_asso(chunks)\n",
    "        elif value == 3 :\n",
    "            merge_asso_pd(chunks)\n",
    "        elif value == 4 :\n",
    "            print(\"See you...\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    #shDir = make_dir(scriptDir + \"assoQT_\"+phenotype +\"/\")\n",
    "    #mergeDir = make_dir(outDir + \"assoMERGEs/\")\n",
    "    #traitDir = outDir+\"assoRESULTs/\"+version+\"_\"+concept+\"_\"+phenotype + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exmaple codes and Data to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('sample.tar.gz', compression='gzip', header=0, sep=' ', quotechar='\"', error_bad_lines=False)\n",
    "df = pd.read_csv(\"C:/Users/user/Downloads/All_2017_BMI_BBJ_autosome.txt.gz\",header = 0,sep='\\t',error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>CHR</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Frq</th>\n",
       "      <th>Rsq</th>\n",
       "      <th>BETA</th>\n",
       "      <th>SE</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr10_103577643</td>\n",
       "      <td>10</td>\n",
       "      <td>103577643</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-0.006703</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>0.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr10_104678841</td>\n",
       "      <td>10</td>\n",
       "      <td>104678841</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.044190</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10_106151962</td>\n",
       "      <td>10</td>\n",
       "      <td>106151962</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.538900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr10_111967649</td>\n",
       "      <td>10</td>\n",
       "      <td>111967649</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr10_119805686</td>\n",
       "      <td>10</td>\n",
       "      <td>119805686</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.670700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SNP  CHR        POS REF ALT     Frq    Rsq      BETA        SE  \\\n",
       "0  chr10_103577643   10  103577643   C   T  0.0302  0.995 -0.006703  0.010480   \n",
       "1  chr10_104678841   10  104678841   G   A  0.0198  0.759 -0.044190  0.014610   \n",
       "2  chr10_106151962   10  106151962   C   G  0.1394  0.820  0.003471  0.005649   \n",
       "3  chr10_111967649   10  111967649   C   G  0.0295  0.928  0.008321  0.010850   \n",
       "4  chr10_119805686   10  119805686   T   G  0.0184  0.982 -0.005624  0.013230   \n",
       "\n",
       "          P  \n",
       "0  0.522500  \n",
       "1  0.002493  \n",
       "2  0.538900  \n",
       "3  0.443100  \n",
       "4  0.670700  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped = pd.read_csv(\"C:/Users/user/Desktop/KCDC/association/KCHIP130K_transformation_hematological_20190903.ped\",delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAM_ID', 'IND_ID', 'FAT_ID', 'MOT_ID', 'age', 'sex', 'cohort', 'wbc',\n",
       "       'rbc', 'hb', 'hct', 'plat', 'mcv', 'mch', 'mchc', 'smk', 'WBC_res',\n",
       "       'WBC_z', 'RBC_res', 'RBC_z', 'PLAT_res', 'PLAT_z', 'HB_res', 'HB_z',\n",
       "       'HCT_res', 'HCT_z', 'MCV_res', 'MCV_z', 'MCH_res', 'MCH_z', 'MCHC_res',\n",
       "       'MCHC_z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WBC_z', 'RBC_z', 'PLAT_z', 'HB_z', 'HCT_z', 'MCV_z', 'MCH_z', 'MCHC_z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x : \"_z\" in x,ped.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WBC_z', 'RBC_z', 'PLAT_z', 'HB_z', 'HCT_z', 'MCV_z', 'MCH_z', 'MCHC_z']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in ped.columns if \"_z\" in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read File : c:/Users/user/Desktop/KCDC/BMI_association/imputation.IMPUTE4.POS.50K_20181114_Final.txt\n",
      "[['REFPANEL', 'IMPUTATION'], ['chr1_10178_5000000', 'chr1_10235_1891206'], ['chr1_10178_5000000', 'chr1_1891207_3156922'], ['chr1_10178_5000000', 'chr1_3156923_4581776'], ['chr1_10178_5000000', 'chr1_4581777_4999954']]\n",
      "\n",
      "chunks : \n",
      "['chr1_10235_1891206', 'chr1_1891207_3156922', 'chr1_3156923_4581776', 'chr1_4581777_4999954', 'chr1_5000010_6381153']\n",
      "\n",
      "chunksSplit : \n",
      "[['chr1', '10235', '1891206'], ['chr1', '1891207', '3156922'], ['chr1', '3156923', '4581776'], ['chr1', '4581777', '4999954'], ['chr1', '5000010', '6381153']]\n"
     ]
    }
   ],
   "source": [
    "Chunk = \"c:/Users/user/Desktop/KCDC/BMI_association/imputation.IMPUTE4.POS.50K_20181114_Final.txt\"\n",
    "Ori_chunksfile = [f.split(\"\\t\") for f in fileRead(Chunk)]\n",
    "print(Ori_chunksfile[0:5])\n",
    "chunks = [r[1] for r in Ori_chunksfile[1:]]\n",
    "print(\"\\nchunks : \")\n",
    "print(chunks[0:5])\n",
    "chunksSplit = [r.split(\"_\") for r in chunks]\n",
    "print(\"\\nchunksSplit : \")\n",
    "print(chunksSplit[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please, Select option you want.\n",
      "1. Make Shell scipt\n",
      "2. Merge result file\n",
      "3. Nothing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while\n",
      "please, Select option you want.\n",
      "1. Make Shell scipt\n",
      "2. Merge result file\n",
      "3. Nothing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input :  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while\n",
      "please, Select option you want.\n",
      "1. Make Shell scipt\n",
      "2. Merge result file\n",
      "3. Nothing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input :  3\n"
     ]
    }
   ],
   "source": [
    "while(print_option() !=3):\n",
    "    print(\"while\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 : \n",
      "   name  age\n",
      "0   Kim   10\n",
      "1   Lee   20\n",
      "2  Choi   19\n",
      "3   Son   29\n",
      "df2 : \n",
      "   name  age\n",
      "0   Lee   20\n",
      "1  Park   99\n",
      "Merge (concat)  : \n",
      "   name  age\n",
      "0   Kim   10\n",
      "1   Lee   20\n",
      "2  Choi   19\n",
      "3   Son   29\n",
      "4   Lee   20\n",
      "5  Park   99\n",
      "   name  age\n",
      "0   Kim   10\n",
      "1   Lee   20\n",
      "2  Choi   19\n",
      "3   Son   29\n",
      "4  Park   99\n"
     ]
    }
   ],
   "source": [
    "name1 = pd.Series([\"Kim\",\"Lee\",\"Choi\",\"Son\"])\n",
    "age1 = pd.Series([10,20,19,29])\n",
    "df1 = pd.DataFrame({\"name\" : name1,\"age\" : age1})\n",
    "print(\"df1 : \")\n",
    "print(df1)\n",
    "\n",
    "name2 = pd.Series([\"Lee\",\"Park\"])\n",
    "age2 = pd.Series([20,99])\n",
    "df2 = pd.DataFrame({\"name\":name2,\"age\":age2})\n",
    "print(\"df2 : \")\n",
    "print(df2)\n",
    "\n",
    "print(\"Merge (concat)  : \")\n",
    "merge_df = pd.concat([df1,df2],axis = 0,ignore_index=True)\n",
    "print(merge_df)\n",
    "\n",
    "merge_df = pd.merge(df1,df2,\"outer\")\n",
    "print(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.core.reshape.merge.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.core.reshape.concat.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from 'C:\\\\Users\\\\user\\\\Python\\\\Anaconda\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
